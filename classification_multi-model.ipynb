{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "about-heavy",
   "metadata": {},
   "source": [
    "## 0. Libarary 불러오기 및 경로설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cubic-scoop",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision.models as models\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import wandb\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "built-elevation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터셋 폴더 경로를 지정해주세요.\n",
    "train_dir = '/opt/ml/input/data/train'\n",
    "test_dir = '/opt/ml/input/data/eval'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quiet-organizer",
   "metadata": {},
   "source": [
    "## 1. Model 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c46f635e-e487-47e2-8241-f13218dc6bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "\n",
    "class MyNet(nn.Module):\n",
    "    def __init__(self ,num_classes: int = 1000):\n",
    "        super(MyNet, self).__init__()\n",
    "        self.model = models.resnet18(pretrained=True)\n",
    "        self.fc2 = nn.Linear(1000,num_classes)\n",
    "    def forward(self,x):\n",
    "        x = self.model(x)\n",
    "        return self.fc2(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "domestic-channels",
   "metadata": {},
   "source": [
    "## 2. Test Dataset 정의 (Gender, Mask, Age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "extensive-north",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenderDataset(Dataset):\n",
    "    def __init__(self, img_paths, transform, train):\n",
    "        self.img_paths = img_paths\n",
    "        self.transform = transform\n",
    "        self.train = train\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.img_paths[index])\n",
    "        label = self.process_labels(self.img_paths[index])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        if self.train:\n",
    "            return image,label\n",
    "        else:\n",
    "            return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "    \n",
    "    def process_labels(self,path):\n",
    "        info,mask = path.split('/')[-2:]\n",
    "        _,gender,race,age = info.split('_')\n",
    "        mask = mask.split('.')[0]\n",
    "        label = {'female':0,'male':1}\n",
    "        \n",
    "        return label[gender]\n",
    "    \n",
    "class MaskDataset(Dataset):\n",
    "    def __init__(self, img_paths, transform, train):\n",
    "        self.img_paths = img_paths\n",
    "        self.transform = transform\n",
    "        self.train = train\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.img_paths[index])\n",
    "        label = self.process_labels(self.img_paths[index])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        if self.train:\n",
    "            return image,label\n",
    "        else:\n",
    "            return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "    \n",
    "    def process_labels(self,path):\n",
    "        info,mask = path.split('/')[-2:]\n",
    "        _,gender,race,age = info.split('_')\n",
    "        mask = mask.split('.')[0]\n",
    "        if mask[:-1]=='mask':\n",
    "            mask='mask'\n",
    "        label = {'incorrect_mask':0,'mask':1,'normal':2}\n",
    "        \n",
    "        return label[mask]\n",
    "    \n",
    "class AgeDataset(Dataset):\n",
    "    def __init__(self, img_paths, transform, train):\n",
    "        self.img_paths = img_paths\n",
    "        self.transform = transform\n",
    "        self.train = train\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.img_paths[index])\n",
    "        label = self.process_labels(self.img_paths[index])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        if self.train:\n",
    "            return image,label\n",
    "        else:\n",
    "            return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "    \n",
    "    def process_labels(self,path):\n",
    "        info,mask = path.split('/')[-2:]\n",
    "        _,gender,race,age = info.split('_')\n",
    "        age=int(age)\n",
    "        if age<30:\n",
    "            return 0\n",
    "        elif 30<=age<60:\n",
    "            return 1\n",
    "        else:\n",
    "            return 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9152197c-35fe-43ee-a7a2-6d34f5633daf",
   "metadata": {},
   "source": [
    "## 3. data 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "929a5969-8e0d-475c-bfc5-bd93b800d1c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data..\n",
      "test 개수: 1890\n",
      "train 개수: 17010\n"
     ]
    }
   ],
   "source": [
    "# meta 데이터와 이미지 경로를 불러옵니다.\n",
    "train_df = pd.read_csv(os.path.join(train_dir, 'train.csv'))\n",
    "image_dir = os.path.join(train_dir, 'images')\n",
    "\n",
    "# Test Dataset 클래스 객체를 생성하고 DataLoader를 만듭니다.\n",
    "image_paths = [os.path.join(image_dir, img_id) for img_id in train_df.path]\n",
    "\n",
    "img_list=[]\n",
    "for i in image_paths:\n",
    "    for j in os.listdir(i):\n",
    "        if j[0]!='.':\n",
    "            img_list.append(i+'/'+j)\n",
    "\n",
    "train, test = train_test_split(img_list, test_size=0.1, shuffle=True,random_state=1004)\n",
    "\n",
    "\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "                                # transforms.CenterCrop(32),\n",
    "                                # transforms.RandomCrop(32, padding=4),\n",
    "                                # transforms.RandomHorizontalFlip(),\n",
    "                                transforms.Resize((224,224)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5070751592371323, 0.48654887331495095, 0.4409178433670343), (0.2673342858792401, 0.2564384629170883, 0.27615047132568404))])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5070751592371323, 0.48654887331495095, 0.4409178433670343), (0.2673342858792401, 0.2564384629170883, 0.27615047132568404)),\n",
    "])\n",
    "\n",
    "\n",
    "print('==> Preparing data..')\n",
    "train, test = train_test_split(img_list, test_size=0.1, shuffle=False)\n",
    "print(\"test 개수:\",len(test))\n",
    "print(\"train 개수:\",len(train))\n",
    "\n",
    "train_dataset = GenderDataset(train, transform_train,train=True)\n",
    "train_set = DataLoader(train_dataset,shuffle=True)\n",
    "\n",
    "test_dataset = GenderDataset(test, transform_test,train=True)\n",
    "test_set =  DataLoader(test_dataset,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3e33bb-dbbd-40f9-99ec-1ad0e4a16d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/17010 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyNet(\n",
      "  (model): ResNet(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
      "  )\n",
      "  (fc2): Linear(in_features=1000, out_features=3, bias=True)\n",
      ")\n",
      "\n",
      "Epoch: 1\n",
      "LR: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 41/17010 [00:06<31:28,  8.98it/s]  "
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.0001\n",
    "\n",
    "# config={\"epochs\": EPOCHS, \"batch_size\": BATCH_SIZE, \"learning_rate\" : LEARNING_RATE}\n",
    "\n",
    "# wandb.init(project=\"mask_classification\", entity='hyeyoon')\n",
    "\n",
    "net = MyNet(num_classes=3)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "net = net.to(device)\n",
    "print(net)\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(),lr=LEARNING_RATE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch, LR):\n",
    "    if epoch <= 10:\n",
    "        lr = LR     \n",
    "    elif epoch <= 15:\n",
    "        lr = LR * 0.5           \n",
    "    else:\n",
    "        lr = LR * 0.1   \n",
    "            \n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "      \n",
    "\n",
    "# Training\n",
    "def train(epoch):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    print('LR: {:0.6f}'.format(optimizer.param_groups[0]['lr']))\n",
    "    for batch_idx, (inputs, targets) in enumerate(tqdm(train_set)):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "    print('Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "        % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "    \n",
    "    # model save\n",
    "    if epoch%5==0:\n",
    "      torch.save({\n",
    "          'epoch': epoch,\n",
    "          'model_state_dict': net.state_dict(),\n",
    "          'optimizer_state_dict': optimizer.state_dict(),\n",
    "          'loss': train_loss/(batch_idx+1),\n",
    "          \"acc\": 100*correct/total\n",
    "          }, f\"/result/checkpoint/resnet18_e_{epoch}_{loss}.pt\")\n",
    "      \n",
    "#     wandb.log({'train_accuracy': 100*correct/total, 'train_loss': train_loss/(batch_idx+1)})\n",
    "\n",
    "        \n",
    "def test(epoch):\n",
    "    global best_acc\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(tqdm(test_set)):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        print('Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "            % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "        \n",
    "#         wandb.log({'test_accuracy': 100*correct/total, 'test_loss': test_loss/(batch_idx+1)})\n",
    "   \n",
    "start_epoch = 1\n",
    "for epoch in range(start_epoch, start_epoch+EPOCHS):\n",
    "    adjust_learning_rate(optimizer, epoch, LR=LEARNING_RATE)\n",
    "    \n",
    "    train(epoch)\n",
    "    test(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d94191-fdd4-4556-b0e5-64eccaf9ed82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
